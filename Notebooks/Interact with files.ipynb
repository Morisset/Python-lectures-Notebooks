{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The following is to know when this notebook has been run and with which python version.\n",
    "import time, sys\n",
    "print(time.ctime())\n",
    "print(sys.version.split('|')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C: How to read and write files (ASCII and FITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is part of the Python lecture given by Christophe Morisset at IA-UNAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some informations are here: http://www.tutorialspoint.com/python/python_files_io.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a simple ascii file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# numpy is needed in some part of the lecture\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will have to have some files on the hard drive to read them The following notebook cell will write a file in the same directory where the notebook has been started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile data1.dat\n",
    "1   2.3  6   8 star\n",
    "2   3.5  7   9 galaxy\n",
    "3  -4.2  5   7 cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal is to read this file. The first way is to open the file, read it completely in a variable and close the file. Then we can play with the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datafile = open('data1.dat', 'r') # Open the file to read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = datafile.readlines() # The variable data will receive the content of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datafile.close() # Not need anymore of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(type(data)) # The data file is stored in the form of a list, each element of the list corresponding to a row of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(data) # Each row is a string and terminates with \\n, symbol of END OF LINE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(len(data)) # number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(data[0], 'tralala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# In python :\n",
    "for row in data:\n",
    "    print(row),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# In python 3:\n",
    "for row in data:\n",
    "    print(row, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(type(data[0])) # Each element is a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is easy to separate each field with the split command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for row in data:\n",
    "    print(row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# One can also transform the data if the type is known:\n",
    "for row in data:\n",
    "    this_data = row.split()\n",
    "    print('N = {0:2d} f = {1:5.2f} type = {2:>10s}'.format(int(this_data[0]), \n",
    "                                                           float(this_data[1]), \n",
    "                                                           this_data[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# One can even fill a list with the data, by column:\n",
    "N = []\n",
    "f = []\n",
    "type_ = [] # take care, type is a python command, you can erase it if you use it...\n",
    "for row in data:\n",
    "    this_data = row.split()\n",
    "    N.append(int(this_data[0]))\n",
    "    f.append(float(this_data[1]))\n",
    "    type_.append(this_data[4])\n",
    "print(N)\n",
    "print(f)\n",
    "print(type_)\n",
    "N = np.array(N)\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# If the file number of rows is not too big, you can use list comprehension (and even send the result to a numpy array)\n",
    "N = np.array([int(row.split()[0]) for row in data])\n",
    "f = np.array([float(row.split()[1]) for row in data])\n",
    "# Each one of this command scans all the rows, don't use for huge files\n",
    "print(N)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to treat special rows (headers, comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile data2.dat\n",
    "# The following data are for test purpose\n",
    "N    f   x   y type\n",
    "1   2.3  6   8 star\n",
    "2   3.5  7   9 galaxy\n",
    "3  -4.2  5   7 cluster\n",
    "#4  -10.5  5  7 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!cat data2.dat # Just to check that the # comments are also in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has to be read row by row, to be sure that special cases are treated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datafile = open('data2.dat', 'r') # Open the file to read it\n",
    "\n",
    "row = datafile.readline() # this reads only one line\n",
    "first_comment = row\n",
    "print(first_comment, end='')\n",
    "\n",
    "row = datafile.readline() # this reads only one line\n",
    "header = row\n",
    "print(header, end='')\n",
    "\n",
    "data = []\n",
    "while True: # loops until exit by break command\n",
    "    row = datafile.readline()\n",
    "    if row == '':\n",
    "        break\n",
    "    if row[0] != '#' and row[0] != '\\n': # comment lines are skipped\n",
    "        data.append(row)\n",
    "datafile.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "datafile = open('data2.dat', 'r') # Open the file to read it\n",
    "row = datafile.readline() # this reads only one line\n",
    "first_comment = row\n",
    "print(first_comment, end='')\n",
    "row = datafile.readline() # this reads only one line\n",
    "header = row\n",
    "print(header, end='')\n",
    "data = []\n",
    "row = datafile.readline()\n",
    "while row != '': # loops until exit by break command\n",
    "    if row[0] != '#': # comment lines are skipped\n",
    "        data.append(row)\n",
    "    row = datafile.readline()\n",
    "datafile.close()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# very shorter way to deal with the file. No need to look for the end of the file.\n",
    "datafile = open('data2.dat', 'r') # Open the file to read it\n",
    "data = []\n",
    "for row in datafile:\n",
    "    if row[0] != '#': # comment lines are skipped\n",
    "        data.append(row)  \n",
    "datafile.close()\n",
    "print(data)\n",
    "# This way will include the header in the data... Not what we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# very shorter way to deal with the file:\n",
    "# we know that the header is the first no-comment line in the file.\n",
    "datafile = open('data2.dat', 'r') # Open the file to read it\n",
    "data = []\n",
    "comments = [] # we can keep the comments for some usage\n",
    "header_read = False # We will turn it to True once the header is read\n",
    "for row in datafile:\n",
    "    if row[0] != '#': # comment lines are skipped\n",
    "        if not header_read:\n",
    "            header = row\n",
    "            header_read = True # next time, data will be read\n",
    "        else:\n",
    "            data.append(row)\n",
    "    else:\n",
    "        comments.append(row)\n",
    "datafile.close()\n",
    "print(header, end='')\n",
    "print(data)\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Alternative way using \"with\". No need to close the file, done when the \"with\" block is terminated.\n",
    "data = []\n",
    "comments = []\n",
    "header_read = False\n",
    "def change_type(row_split):\n",
    "    # This function change the type of the data read from the file from 5 strings into int, 3 floats and a string\n",
    "    # It also return the result in form of a tuple\n",
    "    return (int(row_split[0]), \n",
    "            float(row_split[1]), \n",
    "            float(row_split[2]), \n",
    "            float(row_split[3]), \n",
    "            row_split[4])\n",
    "with open('data2.dat', 'r') as datafile:\n",
    "    for row in datafile:\n",
    "        if row[0] != '#' and row[0] != '\\n': # comment lines are skipped\n",
    "            if not header_read:\n",
    "                header = row\n",
    "                header_read = True\n",
    "            else:\n",
    "                data.append(change_type(row.split()))\n",
    "        else:\n",
    "            comments.append(row)\n",
    "print(header)\n",
    "print(data)\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We can define the result as a structured array\n",
    "# We use the header to define the field names.\n",
    "# data must be a list of tuples.\n",
    "a = np.array(data, dtype={'names':header.split(), \n",
    "                          'formats':['i4','f16', 'f16', 'f16', 'U10']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Easy access to the columns, by their name\n",
    "print(a['N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(a['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Easy combine the values of columns\n",
    "print(np.sqrt(a['x']**2 + a['y']**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numpy loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fast way for reading the file\n",
    "# One hace to tell to skip the 2 first rows\n",
    "# skiprows \n",
    "b = np.loadtxt('data2.dat', skiprows=2, dtype='i4,f, f, f, U10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The names of the columns are f0, f1, f2, etc\n",
    "b.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using numpy genfromtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fast and versatile way to read the file\n",
    "# the names are taken from the file\n",
    "# The types are defined automatically when reading the columns\n",
    "c = np.genfromtxt('data2.dat', names=True, dtype=None, skip_header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "c['f']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a value of x is missing (not possible with space separator, so we use \",\" as separator):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile data3.dat\n",
    "# The following data are for test purpose\n",
    "N,    f,   x,   y, type\n",
    "1,   2.3,  6,   8, star\n",
    "2,   3000.5,   ,  9, galaxy\n",
    "3,  -4.2,  5,   7, cluster\n",
    "#4,  -10.5,  5,  7, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d = np.genfromtxt('data3.dat', names=True, dtype=None, skip_header=1, \n",
    "                  delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The missing value has been changed to -1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Th emissing value can be set to whatever you want (but non a NaN here, as the typ eis integer, and NaN is a float...)\n",
    "d = np.genfromtxt('data3.dat', names=True, dtype=None, skip_header=1, delimiter=',', \n",
    "                  filling_values=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d['x'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ons can select the columns to be store\n",
    "e = np.genfromtxt('data3.dat', names=True, dtype=None, skip_header=1, \n",
    "                  delimiter=',',usecols=(0,1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ons can select the columns to be store\n",
    "N, f, typ = np.genfromtxt('data3.dat', skip_header=2, \n",
    "                  delimiter=',',usecols=(0,1,4), unpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The resulting array now contains only the given columns\n",
    "print(N)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using recfrom to obtain a record array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Uses the same keywords than genfromtxt\n",
    "f = np.recfromtxt('data3.dat', names=True, dtype=None, skip_header=1, \n",
    "                  delimiter=',',usecols=(\"N\", \"f\", \"type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f.N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed size ascii files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile data4.dat\n",
    "#  Line      Iobs    lambda  relat_error Obs_code\n",
    "H  1  4861A 1.00000    4861. 0.08000  Anabel                               \n",
    "H  1  6563A 2.8667     6563. 0.19467  Anabel                               \n",
    "H  1  4340A 0.4933     4340. 0.03307  Anabel                               \n",
    "H  1  4102A 0.2907     4102. 0.02229  Anabel                               \n",
    "H  1  3970A 0.1800     3970. 0.01253  Anabel                               \n",
    "N  2  6584A 2.1681     6584. 0.08686  Anabel                               \n",
    "N  2 121.7m 0.0044621217000. 0.20000  Liu                                  \n",
    "O  1  6300A 0.0147     6300. 0.00325  Anabel                               \n",
    "TOTL  2326A 0.07900    2326. 0.20000  Adams                                \n",
    "C  2 157.6m 0.00856 1576000. 0.20000  Liu                                  \n",
    "O  1 63.17m 0.13647  631700. 0.10000  Liu                                  \n",
    "O  1 145.5m 0.00446 1455000. 0.200    Liu                                  \n",
    "TOTL  3727A 0.77609    3727. 0.200    Torres-Peimbert                      \n",
    "S II  4070A 0.06174    4070. 0.200    Torres-Peimbert                      \n",
    "S II  4078A 0.06174    4078. 0.200    Torres-Peimbert                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we cannot use SPACE as a separator, as some strings contains spaces.\n",
    "# \"delimiter\" is used to specify the size (in characters in the file) of each variables. \n",
    "# The types must be clearly defined too.\n",
    "obs  = np.genfromtxt('data4.dat', \n",
    "                     dtype=[\"U11\",\"float\",\"float\",\"float\",\"U2\"],\n",
    "                     delimiter=[11,7,10,10,2],\n",
    "                     names = True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obs # The same delimiter (fixed sizes) is applied to the names. May not be what you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Defining the names:\n",
    "obs2  = np.genfromtxt('data4.dat', skip_header=1,\n",
    "                     dtype=None,\n",
    "                     delimiter=[11,7,10,10,2],\n",
    "                     names = ['label', 'i_obs', 'lambda', 'e_obs', 'observer']\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obs2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%%writefile data5.dat\n",
    "#  Line      Iobs    lambda  relat_error Obs_code\n",
    "H  1  4861A 1.00000    4861. 0.08000 x Anabel                               \n",
    "H  1  6563A 2.8667     6563. 0.19467 x Anabel                               \n",
    "H  1  4340A 0.4933     4340. 0.03307 x Anabel                               \n",
    "H  1  4102A 0.2907     4102. 0.02229 x Anabel                               \n",
    "H  1  3970A 0.1800     3970. 0.01253 t Anabel                               \n",
    "N  2  6584A 2.1681           0.08686 x Anabel                               \n",
    "N  2 121.7m 0.00446 1217000. 0.20000 g Liu                                  \n",
    "O  1  6300A 0.0147     6300. 0.00325 t Anabel                               \n",
    "TOTL  2326A 0.07900    2326. 0.20000 g Adams                                \n",
    "C  2 157.6m 0.00856 1576000. 0.20000 t Liu                                  \n",
    "O  1 63.17m 0.13647  631700. 0.10000 g Liu                                  \n",
    "O  1 145.5m 0.00446 1455000. 0.200   g Liu                                  \n",
    "TOTL  3727A 0.77609    3727. 0.200   g Torres-Peimbert                      \n",
    "S II  4070A 0.06174    4070. 0.200   g Torres-Peimbert                      \n",
    "S II  4078A 0.06174    4078. 0.200   g Torres-Peimbert   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Here we want to skip one column:\n",
    "obs3  = np.genfromtxt('data5.dat', skip_header=1,\n",
    "                     dtype=None,\n",
    "                     delimiter=[11, 8, 9, 9, 2, 2],\n",
    "                     names = ['label', 'i_obs', 'lambda', 'e_obs', 'na', 'observer'],\n",
    "                     usecols = (0, 1, 2, 3, 5)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "obs3['lambda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_obs3 = obs3.view(np.recarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_obs3.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_obs3.lambda # lambda is reserved!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "new_obs3['lambda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using masks on the structured array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mask_observer = (obs3['observer'] == b'An') & (np.isfinite(obs3['lambda']))\n",
    "print(obs3[mask_observer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for o in obs3[mask_observer]:\n",
    "    print('line {0[label]:4s}, wavelength={0[lambda]}A Intensity={0[i_obs]:5.3f}+/-{1:4.1f}%)'.format(o, o['e_obs']*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple \"write\" method from \"open\" class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = open('data10.dat', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f.write('tralala')\n",
    "f.write('trololo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "!cat 'data10.dat' # the writing method put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = open('data11.dat', 'w')\n",
    "f.write('tralala\\n') # \\n to indicate end of line\n",
    "f.write('trololo\\n')\n",
    "f.close()\n",
    "!cat 'data11.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = open('data11.dat', 'a') # Append to the edn of the file\n",
    "f.write('trilili\\n') # \\n to indicate end of line\n",
    "f.write('trululu\\n')\n",
    "f.close()\n",
    "!cat 'data11.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = 'Smith'\n",
    "b = 3\n",
    "with open('data12.dat', 'w') as datafile:\n",
    "    datafile.write(\"\"\"Hola Sr. {0}\n",
    "This is a file\n",
    "with a lot of lines.\n",
    "It is easy to write it.\n",
    "The value of your data is {1}.\n",
    "\"\"\".format(a, b))\n",
    "!cat \"data12.dat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pickle (and cpickle) python specific format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's define some stuffs we want to keep in a file (data and variable names)\n",
    "a = 5\n",
    "b = 'Hola'\n",
    "c = np.array([1,2,3,4,5])\n",
    "def d(x):\n",
    "    \"\"\" Function mia\"\"\"\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle # The module we will use for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump((a,b,c,d), open('Demo.pickle','wb')) # Writing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res = pickle.load(open('Demo.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(res[0])\n",
    "print(res[1])\n",
    "print(res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "res[3](5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a2,b2,c2,d2 = pickle.load(open('Demo.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "d2(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "help(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%timeit res = pickle.load(open('Demo.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "pickle.dump((a,b,c,d), gzip.open('Demo.pklz','wb')) # Writing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "f = gzip.open('Demo.pklz','rb')\n",
    "a, b, c, d = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FITS files"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "What is the FITS format?\n",
    "The FITS format is the most popular way to save and interchange astronomical data. The files are organized in units each of which contains a human readable header and a data. This structure is refereed as HDUs (Header/DATA Unit). \n",
    "\n",
    "A FITS file can contain one or more HDUs, the first of which is called \"primary\" and the rest are called \"extensions\". The primary HDU usually contains 1D spectrum, 2D image or 3D data cube, although any dimension from 0 to 999 are possible. The data are 1, 2 or 4 bytes integers or 4 or 8 bytes real numbers. \n",
    "\n",
    "The extensions can contain or arrays as in the primary HDU or ascii tables or binary tables. \n",
    "If a FITS file contains only tables, it primary HDU does not contain data, but only header. \n",
    "\n",
    "Both headers and data in a FITS file are organized in blocs of 2880 bytes. The header contain 80 bytes lines each of which consists of a keyword of 8 bytes followed in most of the cases by '= ' in the position 9 and 10 and then the value of the keyword. The rest of the line is a comment string beginning with '/'. Each header begins with the following lines\n",
    "\n",
    "SIMPLE  =                    T / file conforms to FITS standard\n",
    "BITPIX  =                   16 / number of bits per data pixel\n",
    "NAXIS   =                    2 / number of data axes\n",
    "NAXIS1  =                  440 / length of data axis 1\n",
    "NAXIS2  =                  300 / length of data axis 2\n",
    "\n",
    "which defines the format of the file as standard FITS, the data format and the dimensions of the stored data. \n",
    "\n",
    "One block of 2880 bytes contains 36 lines of 80 characters per line. The header can have several blocks of 36 lines. The last block is identified by the presence of the keyword 'END' The next 2880 bytes block contains the first part of the data. The empty lines after 'END' keyword are filled with blanks and the unused bytes from the end of the data to the end of the 2880 bytes block are filled with NULLs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import astropy\n",
    "print(astropy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# All of the functionality of PyFITS is now available in Astropy\n",
    "# from astropy.io import fits as pyfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual here: https://pythonhosted.org/pyfits/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use one FITS files from San Pedro Martir echelle spectrograph. The file can be downloaded from: https://github.com/Morisset/Python-lectures-Notebooks/raw/master/Notebooks/n10017o.fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdulist = fits.open('n10017o.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The result hdulist is a list of HDU objects. \n",
    "# In the case of a simple file, there is only one primary HDU so the list contains only one element\n",
    "len(hdulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The information on what the file contains can be obtained by calling the info() method:\n",
    "hdulist.info()\n",
    "# The table said that there is only a primary HDU which contains 2154 X 2048 image with data stored in 2 bytes (16 bits) integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# As described above, the HDU (header/data unit) contains header and data. The header is a dictionary. \n",
    "# To see what keywords were used in the header one can do:\n",
    "list(hdulist[0].header.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# and to get the value of a given keyword :\n",
    "hdulist[0].header['OBJECT'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hdulist[0].header\n",
    "hh?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdulist[0].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The header can be printed as it appears in the file by\n",
    "print(hdulist[0].header.cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The data in the file are accessible with\n",
    "data = hdulist[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# and can be seen with [we need to import matplotlib.pyplot as plt before running this]:\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "f, ax = plt.subplots(figsize=(15,15))\n",
    "ax.imshow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# A column from the data can be plotted with \n",
    "plt.plot(data[:,1000])\n",
    "# where I am plotting the column number 1000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# In the same way a line from the data is plotted with: \n",
    "plt.plot(data[1000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# For this example I'll use a spectrum obtain with the high dispersion camera on board of IUE. \n",
    "# The file is opened as usual:\n",
    "hdulist = fits.open('swp04345.mxhi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file is there: https://github.com/Morisset/Python-lectures-Notebooks/raw/master/Notebooks/swp04345.mxhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#but now hdulist has 2 elements (2 header/data units):\n",
    "len(hdulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# We can see that the primary header has dimension (), son does not contain any data. \n",
    "# The data are in the extension.\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The first header contains the minimal infirmation:\n",
    "print(hdulist[0].header.cards[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The number of axis is 0 which means there is no data block in the primary HDU. \n",
    "# The header of the second HDU begins with the keyword XTENSION and with the specification of the data\n",
    "print(hdulist[1].header.cards[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# To progress further we need to know what is in the table. \n",
    "# As usual, the columns have names and type of the stored data. \n",
    "# These information can be obtained using the column attribute of hdulist:\n",
    "cols = hdulist[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# the cols.info returns the names of the columns and the information of their format and units.\n",
    "cols.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# The data are available using (this example is NOT the right way of plotting the data, it's just an example) \n",
    "# and don't forget to import numpy as np to have np.arange working]:\n",
    "\n",
    "data1 = hdulist[1].data\n",
    "DTs =  data1.ABS_CAL\n",
    "WLs = data1.WAVELENGTH\n",
    "DWs = data1.DELTAW\n",
    "for WL, DW, DT in zip(WLs, DWs, DTs):\n",
    "    plt.plot(WL + np.arange(len(DT)) * DW, DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing FITS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creation of numpy array with the data. \n",
    "x = np.arange(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Creation of the HDU from the data. \n",
    "hdu = fits.PrimaryHDU(x)\n",
    "print(hdu.header.cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#Adding additional keywords to the header. \n",
    "# The automatically created header contains only the required minimum of keywords. \n",
    "# If additional keywords are needed they are added with:\n",
    "hdu.header['testkey'] = (0.001,'some test value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(hdu.header.cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdulist = fits.HDUList([hdu])\n",
    "hdulist.writeto('new.fits', overwrite=True) \n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to deal with FITS tables is to use the ATpy library, we'll see this later"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
