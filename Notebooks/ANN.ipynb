{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the classical libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries for the Artificial Network. Here we work with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff to perform the polynomial fit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Import tool to compute rms\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Import stuff for the ANN\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function we want to interpolate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_fun(x):\n",
    "    return np.cos(1.5 * np.pi * x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some parameters. The X_train and y_train sets are used to determine the polynome coefficients and also to train the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random seed to reproduce the results\n",
    "np.random.seed(0)\n",
    "\n",
    "# The number of points used to fit the function\n",
    "n_samples = 30\n",
    "\n",
    "# Noise to be added to the points used to fit the function\n",
    "noise = 0.1\n",
    "\n",
    "# The training set: n_samples X points, with the noisy correspoing y  \n",
    "X = np.sort(np.random.rand(n_samples))\n",
    "y = true_fun(X) + np.random.randn(n_samples) * noise\n",
    "X_train = X\n",
    "y_train_true = y\n",
    "\n",
    "# The set of points on which the prediction will be done, to verify the fit quality\n",
    "X_test = np.linspace(0, 1, 100)\n",
    "y_test_true = true_fun(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the train data with a polynome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree = 2\n",
    "p = np.poly1d(np.polyfit(X_train, y_train_true, degree))\n",
    "y_train = p(X_train)\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_train_true))\n",
    "y_test = p(X_test)\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_test_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the original data, the polynomial fit and the true function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(X_test, y_test, label=\"Model prediction\", ls=':')\n",
    "ax.plot(X_test, y_test_true, label=\"True function\")\n",
    "ax.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"Degree {}\\n RMS train: {:.3f}, test: {:.3f}\".format(degree,\n",
    "             rms_train, rms_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Neural Network is used on the same data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Multi-layer Perceptron regressor.\n",
    "# The size of the red is the minimum: only 2 neurons.\n",
    "# The hyper parameters are used to tunne the network\n",
    "ANN = MLPRegressor(hidden_layer_sizes=(2,), \n",
    "                   tol=1e-6, \n",
    "                   max_iter=10000, \n",
    "                   activation='relu',\n",
    "                   solver='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The ANN is trained with the same data than the previous polynomial fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANN.fit(X_train[..., np.newaxis], y_train_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN is used to predict the values. First for the training set, then for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ANN.predict(X_train[..., np.newaxis])\n",
    "rms_train = np.sqrt(mean_squared_error(y_train, y_train_true))\n",
    "y_test = ANN.predict(X_test[..., np.newaxis])\n",
    "rms_test = np.sqrt(mean_squared_error(y_test, y_test_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The values of the weigths and the biases are accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ANN.coefs_, '\\n', ANN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.plot(X_test, y_test, label=\"Model\")\n",
    "ax.plot(X_test, y_test_true, label=\"True function\")\n",
    "\n",
    "ax.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_xlim((0, 1))\n",
    "ax.set_ylim((-2, 2))\n",
    "ax.legend(loc=\"best\")\n",
    "ax.set_title(\"ANN\\n RMS train: {:.3f}, test: {:.3f}\".format(\n",
    "             rms_train, rms_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now 3 values are used for the order of the polynom and for the size of the ANN, and comparison is plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 3, figsize=(14, 10))\n",
    "\n",
    "degrees = [1, 4, 15]\n",
    "for i in range(len(degrees)):\n",
    "    ax = axes[0,i]\n",
    "    p = np.poly1d(np.polyfit(X_train, y_train_true, degrees[i]))\n",
    "    y_train = p(X_train)\n",
    "    rms_train = np.sqrt(mean_squared_error(y_train,y_train_true))\n",
    "    y_test = p(X_test)\n",
    "    rms_test = np.sqrt(mean_squared_error(y_test,y_test_true))\n",
    "    ax.plot(X_test, y_test, label=\"Model\")\n",
    "    ax.plot(X_test, y_test_true, label=\"True function\")\n",
    "    ax.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_xlim((0, 1))\n",
    "    ax.set_ylim((-2, 2))\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_title(\"Degree {}\\n RMS train: {:.3f}, test: {:.3f}\".format( degrees[i],\n",
    "                 rms_train, rms_test))\n",
    "    \n",
    "hidden_layer_sizes_set = ( (3,), (10, 10), (100, 100))\n",
    "hidden_layer_sizes_strs = ('3', '10-10', '100-100')\n",
    "\n",
    "# The inputs are scaled to help the ANN\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[..., np.newaxis])\n",
    "X_train_scaled = scaler.transform(X_train[..., np.newaxis])\n",
    "X_test_scaled = scaler.transform(X_test[..., np.newaxis])\n",
    "\n",
    "for i in range(len(hidden_layer_sizes_set)):\n",
    "    ANN = MLPRegressor(hidden_layer_sizes=hidden_layer_sizes_set[i], \n",
    "                       tol=1e-6, \n",
    "                       max_iter=10000, \n",
    "                       activation='relu',\n",
    "                       solver='adam')\n",
    "    \n",
    "    ANN.fit(X_train_scaled, y_train_true)\n",
    "    y_train = ANN.predict(X_train_scaled)\n",
    "    rms_train = np.sqrt(mean_squared_error(y_train, y_train_true))\n",
    "    y_test = ANN.predict(X_test_scaled)\n",
    "    rms_test = np.sqrt(mean_squared_error(y_test, y_test_true))\n",
    "    ax = axes[1,i]\n",
    "    ax.plot(X_test, y_test, label=\"Model\")\n",
    "    ax.plot(X_test, y_test_true, label=\"True function\")\n",
    "    ax.scatter(X, y, edgecolor='b', s=20, label=\"Samples\")\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_xlim((0, 1))\n",
    "    ax.set_ylim((-2, 2))\n",
    "    ax.set_title(\"ANN = {}\\n RMS train: {:.3f}, test: {:.3f}\".format(hidden_layer_sizes_strs[i],\n",
    "                 rms_train, rms_test))\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
