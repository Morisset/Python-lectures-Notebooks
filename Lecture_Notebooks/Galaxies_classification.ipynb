{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Galaxies_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "de5cr_D68W_9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras import regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJ-PTAw5HboN"
      },
      "source": [
        "def tvscale(img):\n",
        "  plt.rcParams['figure.figsize'] = [6,6]\n",
        "  imgplot = plt.imshow(img, interpolation='none', cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDkBmynOJhWT"
      },
      "source": [
        "try:\n",
        "  X1 = np.load('./cosmo-late.npy')\n",
        "except:\n",
        "  !wget https://github.com/Morisset/Python-lectures-Notebooks/raw/master/Notebooks/cosmo-early.npy\n",
        "  X1 = np.load('./cosmo-late.npy')\n",
        "try:\n",
        "  X2 = np.load('./cosmo-early.npy')\n",
        "except:\n",
        "  !wget https://github.com/Morisset/Python-lectures-Notebooks/raw/master/Notebooks/cosmo-late.npy\n",
        "  X2 = np.load('./cosmo-early.npy')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2Bhb-KEJrvs"
      },
      "source": [
        "#tvscale(X1[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEEj6rTgHwIj",
        "outputId": "abb69746-40df-456e-da3a-43f0b68ba93e"
      },
      "source": [
        "#-- Definition of the Neural Network\n",
        "input_img = Input(shape=(128, 128, 3))\n",
        "\n",
        "activ = 'tanh'\n",
        "\n",
        "x = Conv2D(filters=16, kernel_size=(3,3), activation=activ, padding='same')(input_img) #-- 128, 128, 3 -> 128, 128, 16\n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x) #-- 128, 128, 16 -> 64, 64, 16\n",
        "\n",
        "x = Conv2D(filters=32, kernel_size=(3,3), activation=activ, padding='same')(x) #-- 64, 64, 16 -> 64, 64, 32\n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x) #-- 64, 64, 32 -> 32, 32, 32\n",
        "\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), activation=activ, padding='same')(x) #-- 32, 32, 32 -> 32, 32, 64\n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x) #-- 32, 32, 64 -> 16, 16, 64\n",
        "\n",
        "x = Conv2D(filters=128, kernel_size=(3,3), activation=activ, padding='same')(x) #-- \n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x) #-- \n",
        "\n",
        "x = Conv2D(filters=256, kernel_size=(3,3), activation=activ, padding='same')(x) #-- \n",
        "x = MaxPooling2D(pool_size=(2,2), padding='same')(x) #-- \n",
        "\n",
        "x = Flatten()(x) #-- 16, 16, 64 -> 16,384\n",
        "x = Dense(32, activation=activ)(x)\n",
        "x = Dense(16, activation=activ)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "out = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=input_img, outputs=out)\n",
        "model.compile(loss='mse', optimizer='adam', metrics='mse')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 128, 128, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_23 (MaxPooling (None, 64, 64, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_24 (Conv2D)           (None, 64, 64, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_24 (MaxPooling (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_25 (MaxPooling (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_26 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 32)                131104    \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 524,257\n",
            "Trainable params: 524,257\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2obwFhK3H5N9"
      },
      "source": [
        "#-- Create training sets\n",
        "\n",
        "X = np.concatenate((X1, X2), axis=0) / 256.\n",
        "Y = np.zeros(X.shape[0])\n",
        "Y[0:len(X1)] = 1\n",
        "\n",
        "rand_ind = np.arange(0, X.shape[0])\n",
        "\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(rand_ind)\n",
        "\n",
        "X = X[rand_ind]\n",
        "Y = Y[rand_ind]\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "392NLQnaQJEL",
        "outputId": "19a406c1-494a-4184-ca1b-4aea596ce198"
      },
      "source": [
        "X_train = X[50:]\n",
        "Y_train = Y[50:]\n",
        "\n",
        "X_test = X[0:50]\n",
        "Y_test = Y[0:50]\n",
        "\n",
        "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(552, 128, 128, 3) (552,) (50, 128, 128, 3) (50,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlSYQMlLSlVj",
        "outputId": "74f7232b-88a2-42da-ddb4-21969e4ee0f6"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=32, epochs=100, shuffle=True)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "18/18 [==============================] - 1s 17ms/step - loss: 0.2409 - mse: 0.2409\n",
            "Epoch 2/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0760 - mse: 0.0760\n",
            "Epoch 3/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0703 - mse: 0.0703\n",
            "Epoch 4/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0328 - mse: 0.0328\n",
            "Epoch 5/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0176 - mse: 0.0176\n",
            "Epoch 6/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0163 - mse: 0.0163\n",
            "Epoch 7/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0207 - mse: 0.0207\n",
            "Epoch 8/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0202 - mse: 0.0202\n",
            "Epoch 9/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0048 - mse: 0.0048\n",
            "Epoch 10/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0137 - mse: 0.0137\n",
            "Epoch 11/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - mse: 0.0060\n",
            "Epoch 12/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0106 - mse: 0.0106\n",
            "Epoch 13/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0127 - mse: 0.0127\n",
            "Epoch 14/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0099 - mse: 0.0099\n",
            "Epoch 15/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 16/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0068 - mse: 0.0068\n",
            "Epoch 17/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0175 - mse: 0.0175\n",
            "Epoch 18/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0173 - mse: 0.0173\n",
            "Epoch 19/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mse: 0.0048\n",
            "Epoch 20/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0019 - mse: 0.0019\n",
            "Epoch 21/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 6.1917e-04 - mse: 6.1917e-04\n",
            "Epoch 22/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0028 - mse: 0.0028\n",
            "Epoch 23/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 3.1098e-04 - mse: 3.1098e-04\n",
            "Epoch 24/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.3188e-04 - mse: 2.3188e-04\n",
            "Epoch 25/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.9111e-04 - mse: 1.9111e-04\n",
            "Epoch 26/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.6485e-04 - mse: 1.6485e-04\n",
            "Epoch 27/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.4532e-04 - mse: 2.4532e-04\n",
            "Epoch 28/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.4740e-04 - mse: 1.4740e-04\n",
            "Epoch 29/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 2.2979e-04 - mse: 2.2979e-04\n",
            "Epoch 30/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.4887e-04 - mse: 1.4887e-04\n",
            "Epoch 31/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.5537e-04 - mse: 1.5537e-04\n",
            "Epoch 32/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.1872e-04 - mse: 1.1872e-04\n",
            "Epoch 33/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.1784e-04 - mse: 1.1784e-04\n",
            "Epoch 34/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.4178e-04 - mse: 1.4178e-04\n",
            "Epoch 35/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.4574e-04 - mse: 1.4574e-04\n",
            "Epoch 36/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.2568e-04 - mse: 1.2568e-04\n",
            "Epoch 37/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.2018e-04 - mse: 1.2018e-04\n",
            "Epoch 38/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.1283e-04 - mse: 1.1283e-04\n",
            "Epoch 39/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.1332e-04 - mse: 1.1332e-04\n",
            "Epoch 40/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.2634e-04 - mse: 1.2634e-04\n",
            "Epoch 41/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.1499e-04 - mse: 1.1499e-04\n",
            "Epoch 42/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 1.6982e-04 - mse: 1.6982e-04\n",
            "Epoch 43/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.7262e-04 - mse: 1.7262e-04\n",
            "Epoch 44/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.2214e-04 - mse: 1.2214e-04\n",
            "Epoch 45/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.0802e-04 - mse: 1.0802e-04\n",
            "Epoch 46/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 2.4165e-04 - mse: 2.4165e-04\n",
            "Epoch 47/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 6.9644e-05 - mse: 6.9644e-05\n",
            "Epoch 48/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 8.6321e-05 - mse: 8.6321e-05\n",
            "Epoch 49/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 8.3983e-05 - mse: 8.3983e-05\n",
            "Epoch 50/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 9.7515e-05 - mse: 9.7515e-05\n",
            "Epoch 51/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 9.7930e-05 - mse: 9.7930e-05\n",
            "Epoch 52/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 8.0650e-05 - mse: 8.0650e-05\n",
            "Epoch 53/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 7.7502e-05 - mse: 7.7502e-05\n",
            "Epoch 54/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.0460e-04 - mse: 1.0460e-04\n",
            "Epoch 55/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 9.9678e-05 - mse: 9.9678e-05\n",
            "Epoch 56/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 7.6288e-05 - mse: 7.6288e-05\n",
            "Epoch 57/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 7.7261e-05 - mse: 7.7261e-05\n",
            "Epoch 58/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 5.2938e-05 - mse: 5.2938e-05\n",
            "Epoch 59/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 7.3130e-05 - mse: 7.3130e-05\n",
            "Epoch 60/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 5.8770e-05 - mse: 5.8770e-05\n",
            "Epoch 61/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 5.2799e-05 - mse: 5.2799e-05\n",
            "Epoch 62/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 6.2128e-05 - mse: 6.2128e-05\n",
            "Epoch 63/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 7.1771e-05 - mse: 7.1771e-05\n",
            "Epoch 64/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 4.7026e-05 - mse: 4.7026e-05\n",
            "Epoch 65/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.6294e-04 - mse: 1.6294e-04\n",
            "Epoch 66/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 9.4678e-05 - mse: 9.4678e-05\n",
            "Epoch 67/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 7.3173e-05 - mse: 7.3173e-05\n",
            "Epoch 68/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 8.2679e-05 - mse: 8.2679e-05\n",
            "Epoch 69/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 7.0308e-05 - mse: 7.0308e-05\n",
            "Epoch 70/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 8.2245e-05 - mse: 8.2245e-05\n",
            "Epoch 71/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 5.7815e-05 - mse: 5.7815e-05\n",
            "Epoch 72/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.1158e-04 - mse: 1.1158e-04\n",
            "Epoch 73/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.6713e-04 - mse: 2.6713e-04\n",
            "Epoch 74/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 4.8651e-05 - mse: 4.8651e-05\n",
            "Epoch 75/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 4.1419e-05 - mse: 4.1419e-05\n",
            "Epoch 76/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 8.1125e-05 - mse: 8.1125e-05\n",
            "Epoch 77/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.4391e-05 - mse: 3.4391e-05\n",
            "Epoch 78/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.9819e-05 - mse: 3.9819e-05\n",
            "Epoch 79/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 9.5635e-05 - mse: 9.5635e-05\n",
            "Epoch 80/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 5.2325e-05 - mse: 5.2325e-05\n",
            "Epoch 81/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 4.5321e-05 - mse: 4.5321e-05\n",
            "Epoch 82/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 8.2695e-05 - mse: 8.2695e-05\n",
            "Epoch 83/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 4.2059e-05 - mse: 4.2059e-05\n",
            "Epoch 84/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 6.5274e-05 - mse: 6.5274e-05\n",
            "Epoch 85/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.2695e-05 - mse: 3.2695e-05\n",
            "Epoch 86/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.6903e-05 - mse: 3.6903e-05\n",
            "Epoch 87/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.5158e-05 - mse: 3.5158e-05\n",
            "Epoch 88/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 2.9888e-05 - mse: 2.9888e-05\n",
            "Epoch 89/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 5.4357e-05 - mse: 5.4357e-05\n",
            "Epoch 90/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 9.1868e-05 - mse: 9.1868e-05\n",
            "Epoch 91/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.1167e-05 - mse: 3.1167e-05\n",
            "Epoch 92/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.2923e-05 - mse: 3.2923e-05\n",
            "Epoch 93/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 4.1245e-05 - mse: 4.1245e-05\n",
            "Epoch 94/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 4.3778e-05 - mse: 4.3778e-05\n",
            "Epoch 95/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.0990e-05 - mse: 3.0990e-05\n",
            "Epoch 96/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.3894e-05 - mse: 3.3894e-05\n",
            "Epoch 97/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 3.4445e-05 - mse: 3.4445e-05\n",
            "Epoch 98/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.6060e-05 - mse: 2.6060e-05\n",
            "Epoch 99/100\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 4.3090e-05 - mse: 4.3090e-05\n",
            "Epoch 100/100\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.6888e-05 - mse: 2.6888e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UivhnLsSzVG",
        "outputId": "02090f93-8eb0-4b14-bd2f-c22b59e4b388"
      },
      "source": [
        "Y_pred = np.round(model.predict(X_test))[:,0]\n",
        "\n",
        "equal = np.where(Y_pred - Y_test == 0)[0]\n",
        "\n",
        "print(len(equal) / 50)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}